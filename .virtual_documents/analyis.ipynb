import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt
import seaborn as sns
import os


from sklearn.preprocessing import StandardScaler


train = pd.read_csv("train.csv", index_col="id")
test = pd.read_csv("test.csv", index_col="id")
train.head()


train.describe().T[["count","mean","50%","std","min","max"]].round({"mean":3,"std":3})


train.info()


X_columns = ["Age","BP","Max HR","Cholesterol","ST depression"]

rows, cols = 5, 3
plt.figure(figsize=(15, 20))

for i, col in enumerate(X_columns[:rows*cols]):
    plt.subplot(rows, cols, i + 1)
    sns.histplot(
        data=train,
        x=col,
        hue="Heart Disease",
        bins=15
    )
    plt.title(col)

plt.tight_layout()
plt.show()
plt.savefig("hist_plot.png")


X_columns = ["Age","BP","Max HR","Cholesterol","ST depression"]

rows, cols = 5, 3
plt.figure(figsize=(15, 20))

for i, col in enumerate(X_columns[:rows*cols]):
    plt.subplot(rows, cols, i + 1)
    sns.kdeplot(
        data=train,
        x=col,
        hue="Heart Disease",
    )
    plt.title(col)

plt.tight_layout()
plt.show()
plt.savefig("kde_plot.png")


X_columns = train.drop(columns=["Age","BP","Max HR","Cholesterol","ST depression"]).columns

rows, cols = 5, 3
plt.figure(figsize=(15, 20))

for i, col in enumerate(X_columns[:rows*cols]):
    plt.subplot(rows, cols, i + 1)
    sns.countplot(
        data=train,
        x=col,
        hue="Heart Disease",
    )
    plt.title(col)

plt.tight_layout()
plt.show()
plt.savefig("countplot.png")





train["Heart Disease"] = train["Heart Disease"].map({
    "Absence": 0,
    "Presence": 1
})



train[train["Heart Disease"] == 1]["Age"].shape


train[train["Heart Disease"] == 1]["Age"].std()



train["Heart Disease"].value_counts(normalize=True)






train.groupby("Heart Disease")[["Age","BP","Max HR","Cholesterol","ST depression"]].mean()







num_cols = ["Age","BP","Max HR","Cholesterol","ST depression"]

cat_cols = train.drop(columns=num_cols + ["Heart Disease"]).columns

for col in cat_cols:
    print("\n", col)
    print(pd.crosstab(train[col], train["Heart Disease"], normalize="index"))



plt.figure(figsize=(12,10))
cor = train.corr()
sns.heatmap(cor, cmap="coolwarm", annot=True)








# instend of label encoding we need to onehot encode the features
train_onehot = pd.get_dummies(train, columns=cat_cols, drop_first=True).astype(int)
train_onehot.head()


# Noramlize features 

num_cols = ["Age","BP","Max HR","Cholesterol","ST depression"]

scaler = StandardScaler()

train_onehot[num_cols] = scaler.fit_transform(train_onehot[num_cols])


# split in in x and y
X = train_onehot.drop(columns=["Heart Disease"])
y = train_onehot["Heart Disease"]


from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier

log_model = LogisticRegression(max_iter=1000)
rf_model = RandomForestClassifier()
xgb_model = XGBClassifier(use_label_encoder=False, eval_metric="logloss")


from sklearn.model_selection import cross_val_score
scoring="roc_auc"
log_scores = cross_val_score(log_model, X, y, cv=5, scoring="roc_auc")
rf_scores = cross_val_score(rf_model, X, y, cv=5, scoring="roc_auc")
xgb_scores = cross_val_score(xgb_model, X, y, cv=5, scoring="roc_auc")

print("Logistic ROC-AUC:", log_scores.mean())
print("Random Forest ROC-AUC:", rf_scores.mean())
print("XGBoost ROC-AUC:", xgb_scores.mean())



